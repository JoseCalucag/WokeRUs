{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Lending ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "sns.set() \n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "# accepted applicants data file \n",
    "raw_accepted = pd.read_csv('../Archive/accepted_2007_to_2018Q4.csv') \n",
    "# rejected applicants data file\n",
    "raw_rejected = pd.read_csv('../Archive/rejected_2007_to_2018Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Amount Requested Application Date                        Loan Title  \\\n",
       "0        1000.00000       2007-05-26  Wedding Covered but No Honeymoon   \n",
       "1        1000.00000       2007-05-26                Consolidating Debt   \n",
       "2       11000.00000       2007-05-27       Want to consolidate my debt   \n",
       "3        6000.00000       2007-05-27                           waksman   \n",
       "4        1500.00000       2007-05-27                            mdrigo   \n",
       "\n",
       "   Risk_Score Debt-To-Income Ratio Zip Code State Employment Length  \\\n",
       "0   693.00000                  10%    481xx    NM           4 years   \n",
       "1   703.00000                  10%    010xx    MA          < 1 year   \n",
       "2   715.00000                  10%    212xx    MD            1 year   \n",
       "3   698.00000               38.64%    017xx    MA          < 1 year   \n",
       "4   509.00000                9.43%    209xx    MD          < 1 year   \n",
       "\n",
       "   Policy Code  \n",
       "0      0.00000  \n",
       "1      0.00000  \n",
       "2      0.00000  \n",
       "3      0.00000  \n",
       "4      0.00000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Amount Requested</th>\n      <th>Application Date</th>\n      <th>Loan Title</th>\n      <th>Risk_Score</th>\n      <th>Debt-To-Income Ratio</th>\n      <th>Zip Code</th>\n      <th>State</th>\n      <th>Employment Length</th>\n      <th>Policy Code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000.00000</td>\n      <td>2007-05-26</td>\n      <td>Wedding Covered but No Honeymoon</td>\n      <td>693.00000</td>\n      <td>10%</td>\n      <td>481xx</td>\n      <td>NM</td>\n      <td>4 years</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000.00000</td>\n      <td>2007-05-26</td>\n      <td>Consolidating Debt</td>\n      <td>703.00000</td>\n      <td>10%</td>\n      <td>010xx</td>\n      <td>MA</td>\n      <td>&lt; 1 year</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11000.00000</td>\n      <td>2007-05-27</td>\n      <td>Want to consolidate my debt</td>\n      <td>715.00000</td>\n      <td>10%</td>\n      <td>212xx</td>\n      <td>MD</td>\n      <td>1 year</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6000.00000</td>\n      <td>2007-05-27</td>\n      <td>waksman</td>\n      <td>698.00000</td>\n      <td>38.64%</td>\n      <td>017xx</td>\n      <td>MA</td>\n      <td>&lt; 1 year</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1500.00000</td>\n      <td>2007-05-27</td>\n      <td>mdrigo</td>\n      <td>509.00000</td>\n      <td>9.43%</td>\n      <td>209xx</td>\n      <td>MD</td>\n      <td>&lt; 1 year</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#create data copy \n",
    "file_rejected = raw_rejected.copy()\n",
    "file_rejected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id  member_id   loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  68407277        NaN  3600.00000   3600.00000       3600.00000   36 months   \n",
       "1  68355089        NaN 24700.00000  24700.00000      24700.00000   36 months   \n",
       "2  68341763        NaN 20000.00000  20000.00000      20000.00000   60 months   \n",
       "3  66310712        NaN 35000.00000  35000.00000      35000.00000   60 months   \n",
       "4  68476807        NaN 10400.00000  10400.00000      10400.00000   60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
       "0  13.99000    123.03000     C        C4  ...                            NaN   \n",
       "1  11.99000    820.28000     C        C1  ...                            NaN   \n",
       "2  10.78000    432.66000     B        B4  ...                            NaN   \n",
       "3  14.85000    829.90000     C        C5  ...                            NaN   \n",
       "4  22.45000    289.91000     F        F1  ...                            NaN   \n",
       "\n",
       "  hardship_last_payment_amount disbursement_method  debt_settlement_flag  \\\n",
       "0                          NaN                Cash                     N   \n",
       "1                          NaN                Cash                     N   \n",
       "2                          NaN                Cash                     N   \n",
       "3                          NaN                Cash                     N   \n",
       "4                          NaN                Cash                     N   \n",
       "\n",
       "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
       "0                       NaN               NaN             NaN   \n",
       "1                       NaN               NaN             NaN   \n",
       "2                       NaN               NaN             NaN   \n",
       "3                       NaN               NaN             NaN   \n",
       "4                       NaN               NaN             NaN   \n",
       "\n",
       "  settlement_amount settlement_percentage settlement_term  \n",
       "0               NaN                   NaN             NaN  \n",
       "1               NaN                   NaN             NaN  \n",
       "2               NaN                   NaN             NaN  \n",
       "3               NaN                   NaN             NaN  \n",
       "4               NaN                   NaN             NaN  \n",
       "\n",
       "[5 rows x 151 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>member_id</th>\n      <th>loan_amnt</th>\n      <th>funded_amnt</th>\n      <th>funded_amnt_inv</th>\n      <th>term</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>grade</th>\n      <th>sub_grade</th>\n      <th>...</th>\n      <th>hardship_payoff_balance_amount</th>\n      <th>hardship_last_payment_amount</th>\n      <th>disbursement_method</th>\n      <th>debt_settlement_flag</th>\n      <th>debt_settlement_flag_date</th>\n      <th>settlement_status</th>\n      <th>settlement_date</th>\n      <th>settlement_amount</th>\n      <th>settlement_percentage</th>\n      <th>settlement_term</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>68407277</td>\n      <td>NaN</td>\n      <td>3600.00000</td>\n      <td>3600.00000</td>\n      <td>3600.00000</td>\n      <td>36 months</td>\n      <td>13.99000</td>\n      <td>123.03000</td>\n      <td>C</td>\n      <td>C4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Cash</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>68355089</td>\n      <td>NaN</td>\n      <td>24700.00000</td>\n      <td>24700.00000</td>\n      <td>24700.00000</td>\n      <td>36 months</td>\n      <td>11.99000</td>\n      <td>820.28000</td>\n      <td>C</td>\n      <td>C1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Cash</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>68341763</td>\n      <td>NaN</td>\n      <td>20000.00000</td>\n      <td>20000.00000</td>\n      <td>20000.00000</td>\n      <td>60 months</td>\n      <td>10.78000</td>\n      <td>432.66000</td>\n      <td>B</td>\n      <td>B4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Cash</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>66310712</td>\n      <td>NaN</td>\n      <td>35000.00000</td>\n      <td>35000.00000</td>\n      <td>35000.00000</td>\n      <td>60 months</td>\n      <td>14.85000</td>\n      <td>829.90000</td>\n      <td>C</td>\n      <td>C5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Cash</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>68476807</td>\n      <td>NaN</td>\n      <td>10400.00000</td>\n      <td>10400.00000</td>\n      <td>10400.00000</td>\n      <td>60 months</td>\n      <td>22.45000</td>\n      <td>289.91000</td>\n      <td>F</td>\n      <td>F1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Cash</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 151 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#create data copy \n",
    "file_accepted = raw_accepted.copy()\n",
    "file_accepted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 1 .Binary classification model to accept or reject loan application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Only keep those columns that are going to be used for analysis \n",
    " \n",
    "Application Date - date does not play a role in getting rejected or accepted unless you beleive in Numerology \n",
    "Loan Title - For out initial model we have left this out since it did not add a lot of value to the rejected decison. \n",
    "Zip Code - We saw people getting accepted and rejected for teh same zipcodes so we think that zipcode does not have a big impact on loan application\n",
    "Policy Code- This is our target column so we have it but made sure it was all '0'\n",
    "\n",
    "'''\n",
    "file_rejected = file_rejected[['Amount Requested', 'Risk_Score',\n",
    "       'Debt-To-Income Ratio', 'Employment Length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Amount Requested  Risk_Score Debt-To-Income Ratio Employment Length  \\\n",
       "0        1000.00000   693.00000                  10%           4 years   \n",
       "1        1000.00000   703.00000                  10%          < 1 year   \n",
       "2       11000.00000   715.00000                  10%            1 year   \n",
       "3        6000.00000   698.00000               38.64%          < 1 year   \n",
       "4        1500.00000   509.00000                9.43%          < 1 year   \n",
       "\n",
       "   Label_target  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Amount Requested</th>\n      <th>Risk_Score</th>\n      <th>Debt-To-Income Ratio</th>\n      <th>Employment Length</th>\n      <th>Label_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000.00000</td>\n      <td>693.00000</td>\n      <td>10%</td>\n      <td>4 years</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000.00000</td>\n      <td>703.00000</td>\n      <td>10%</td>\n      <td>&lt; 1 year</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11000.00000</td>\n      <td>715.00000</td>\n      <td>10%</td>\n      <td>1 year</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6000.00000</td>\n      <td>698.00000</td>\n      <td>38.64%</td>\n      <td>&lt; 1 year</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1500.00000</td>\n      <td>509.00000</td>\n      <td>9.43%</td>\n      <td>&lt; 1 year</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "file_rejected['Label_target'] = 0\n",
    "file_rejected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    loan_amnt  fico_range_low  fico_range_high      dti emp_length\n",
       "0  3600.00000       675.00000        679.00000  5.91000  10+ years\n",
       "1 24700.00000       715.00000        719.00000 16.06000  10+ years\n",
       "2 20000.00000       695.00000        699.00000 10.78000  10+ years\n",
       "3 35000.00000       785.00000        789.00000 17.06000  10+ years\n",
       "4 10400.00000       695.00000        699.00000 25.37000    3 years"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>fico_range_low</th>\n      <th>fico_range_high</th>\n      <th>dti</th>\n      <th>emp_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3600.00000</td>\n      <td>675.00000</td>\n      <td>679.00000</td>\n      <td>5.91000</td>\n      <td>10+ years</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24700.00000</td>\n      <td>715.00000</td>\n      <td>719.00000</td>\n      <td>16.06000</td>\n      <td>10+ years</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20000.00000</td>\n      <td>695.00000</td>\n      <td>699.00000</td>\n      <td>10.78000</td>\n      <td>10+ years</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35000.00000</td>\n      <td>785.00000</td>\n      <td>789.00000</td>\n      <td>17.06000</td>\n      <td>10+ years</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10400.00000</td>\n      <td>695.00000</td>\n      <td>699.00000</td>\n      <td>25.37000</td>\n      <td>3 years</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Extact the same columms from the  accepted applicant df to match the rejected data set. We will combine this dataset at a later set to make a complete data frame that will be used to train teh classification model. \n",
    "\n",
    "file_accepted = file_accepted[['loan_amnt', 'fico_range_low', 'fico_range_high', 'dti', 'emp_length']]\n",
    "file_accepted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average FICO score for the high and low range of the applicant\n",
    "file_accepted['average'] = (file_accepted['fico_range_low'] + file_accepted['fico_range_high'])*0.5\n",
    "\n",
    "# Drop the FICO high and low scores \n",
    "file_accepted = file_accepted.drop(columns=['fico_range_low','fico_range_high'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    loan_amnt      dti emp_length   average  label_target\n",
       "0  3600.00000  5.91000  10+ years 677.00000             1\n",
       "1 24700.00000 16.06000  10+ years 717.00000             1\n",
       "2 20000.00000 10.78000  10+ years 697.00000             1\n",
       "3 35000.00000 17.06000  10+ years 787.00000             1\n",
       "4 10400.00000 25.37000    3 years 697.00000             1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>dti</th>\n      <th>emp_length</th>\n      <th>average</th>\n      <th>label_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3600.00000</td>\n      <td>5.91000</td>\n      <td>10+ years</td>\n      <td>677.00000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24700.00000</td>\n      <td>16.06000</td>\n      <td>10+ years</td>\n      <td>717.00000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20000.00000</td>\n      <td>10.78000</td>\n      <td>10+ years</td>\n      <td>697.00000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35000.00000</td>\n      <td>17.06000</td>\n      <td>10+ years</td>\n      <td>787.00000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10400.00000</td>\n      <td>25.37000</td>\n      <td>3 years</td>\n      <td>697.00000</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "#Create a target label column for accepted df\n",
    "file_accepted['label_target']=1   \n",
    "file_accepted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for accepted and rejected df\n",
    "file_accepted.rename(columns= {'loan_amnt': 'Loan_Amount', 'dti': 'Debt_income_ratio', 'average': 'Credit_Score', 'label_target': 'Loan_Status', 'emp_length':'Emp_Length'}, inplace=True)\n",
    "\n",
    "file_rejected.rename(columns= {'Amount Requested': 'Loan_Amount', 'Debt-To-Income Ratio': 'Debt_income_ratio', 'Risk_Score': 'Credit_Score', 'Label_target': 'Loan_Status', 'Employment Length':'Emp_Length'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Loan_Amount Debt_income_ratio Emp_Length  Credit_Score  Loan_Status\n",
       "0   1000.00000               10%    4 years     693.00000            0\n",
       "1   1000.00000               10%   < 1 year     703.00000            0\n",
       "2  11000.00000               10%     1 year     715.00000            0\n",
       "3   6000.00000            38.64%   < 1 year     698.00000            0\n",
       "4   1500.00000             9.43%   < 1 year     509.00000            0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loan_Amount</th>\n      <th>Debt_income_ratio</th>\n      <th>Emp_Length</th>\n      <th>Credit_Score</th>\n      <th>Loan_Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000.00000</td>\n      <td>10%</td>\n      <td>4 years</td>\n      <td>693.00000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000.00000</td>\n      <td>10%</td>\n      <td>&lt; 1 year</td>\n      <td>703.00000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11000.00000</td>\n      <td>10%</td>\n      <td>1 year</td>\n      <td>715.00000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6000.00000</td>\n      <td>38.64%</td>\n      <td>&lt; 1 year</td>\n      <td>698.00000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1500.00000</td>\n      <td>9.43%</td>\n      <td>&lt; 1 year</td>\n      <td>509.00000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# rearrange columns in rejected df to concat with the accepted df\n",
    "file_rejected = file_rejected[['Loan_Amount', 'Debt_income_ratio', 'Emp_Length', 'Credit_Score', 'Loan_Status']]\n",
    "file_rejected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Loan_Amount  Debt_income_ratio Emp_Length  Credit_Score  Loan_Status\n",
       "0   1000.00000           10.00000    4 years     693.00000            0\n",
       "1   1000.00000           10.00000   < 1 year     703.00000            0\n",
       "2  11000.00000           10.00000     1 year     715.00000            0\n",
       "3   6000.00000           38.64000   < 1 year     698.00000            0\n",
       "4   1500.00000            9.43000   < 1 year     509.00000            0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loan_Amount</th>\n      <th>Debt_income_ratio</th>\n      <th>Emp_Length</th>\n      <th>Credit_Score</th>\n      <th>Loan_Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000.00000</td>\n      <td>10.00000</td>\n      <td>4 years</td>\n      <td>693.00000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000.00000</td>\n      <td>10.00000</td>\n      <td>&lt; 1 year</td>\n      <td>703.00000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11000.00000</td>\n      <td>10.00000</td>\n      <td>1 year</td>\n      <td>715.00000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6000.00000</td>\n      <td>38.64000</td>\n      <td>&lt; 1 year</td>\n      <td>698.00000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1500.00000</td>\n      <td>9.43000</td>\n      <td>&lt; 1 year</td>\n      <td>509.00000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# remove % from Debt_income_ratio\n",
    "file_rejected['Debt_income_ratio'] = file_rejected['Debt_income_ratio'].str.replace('%','')\n",
    "file_rejected['Debt_income_ratio'] = pd.to_numeric(file_rejected['Debt_income_ratio'])\n",
    "file_rejected.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Loan_Amount                 0\n",
       "Debt_income_ratio           0\n",
       "Emp_Length             951355\n",
       "Credit_Score         18497630\n",
       "Loan_Status                 0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Check number of NaNs in rejected dataset\n",
    "\n",
    "file_rejected.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Loan_Amount              33\n",
       "Debt_income_ratio      1744\n",
       "Emp_Length           146940\n",
       "Credit_Score             33\n",
       "Loan_Status               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Check number of NaNs in accepted dataset\n",
    "\n",
    "file_accepted.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 2113648 succesfull applications and 8992595 unsuccessful applications\n"
     ]
    }
   ],
   "source": [
    "# Drop NaNs from both datasets\n",
    "\n",
    "file_accepted = file_accepted.dropna()\n",
    "file_rejected = file_rejected.dropna()\n",
    "print(f'There are {file_accepted.shape[0]} succesfull applications and {file_rejected.shape[0]} unsuccessful applications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data sets \n",
    "file_accepted.to_csv('../Archive/accepted_data_clean', index=False)\n",
    "file_rejected.to_csv('../Archive/rejected_data_clean', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate the two dataframes to single \n",
    "consolidated = pd.concat([file_accepted, file_rejected], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "< 1 year     8358386\n",
       "10+ years     960253\n",
       "5 years       365812\n",
       "2 years       282099\n",
       "3 years       248095\n",
       "1 year        224209\n",
       "4 years       186245\n",
       "6 years       137652\n",
       "7 years       122446\n",
       "8 years       119819\n",
       "9 years       101227\n",
       "Name: Emp_Length, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Check unique values in Emp_length col\n",
    "consolidated['Emp_Length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     8358386\n",
       "10     960253\n",
       "5      365812\n",
       "2      282099\n",
       "3      248095\n",
       "1      224209\n",
       "4      186245\n",
       "6      137652\n",
       "7      122446\n",
       "8      119819\n",
       "9      101227\n",
       "Name: Emp_Length, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Remove the strings years, <,>,+ from Emp_length\n",
    "\n",
    "consolidated['Emp_Length'] = consolidated['Emp_Length'].replace('10+ years','10')\n",
    "consolidated['Emp_Length'] = consolidated['Emp_Length'].replace('< 1 year','0')\n",
    "consolidated['Emp_Length'] = consolidated['Emp_Length'].replace('1 year','1')\n",
    "consolidated['Emp_Length'] = consolidated['Emp_Length'].str.replace(' years','')\n",
    "consolidated['Emp_Length'] = consolidated['Emp_Length'].replace(' ','')\n",
    "consolidated['Emp_Length'] = pd.to_numeric(consolidated['Emp_Length'])\n",
    "consolidated['Emp_Length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Loan_Amount  Debt_income_ratio     Emp_Length   Credit_Score  \\\n",
       "count 11106243.00000     11106243.00000 11106243.00000 11106243.00000   \n",
       "mean     13132.42598          140.83387        1.55425      641.25526   \n",
       "std      10653.05310        15988.09176        3.17176       87.03325   \n",
       "min          0.00000           -1.00000        0.00000        0.00000   \n",
       "25%       5000.00000            9.89000        0.00000      604.00000   \n",
       "50%      10000.00000           19.65000        0.00000      653.00000   \n",
       "75%      20000.00000           32.80000        0.00000      687.00000   \n",
       "max    1400000.00000     50000031.49000       10.00000      990.00000   \n",
       "\n",
       "         Loan_Status  \n",
       "count 11106243.00000  \n",
       "mean         0.19031  \n",
       "std          0.39255  \n",
       "min          0.00000  \n",
       "25%          0.00000  \n",
       "50%          0.00000  \n",
       "75%          0.00000  \n",
       "max          1.00000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loan_Amount</th>\n      <th>Debt_income_ratio</th>\n      <th>Emp_Length</th>\n      <th>Credit_Score</th>\n      <th>Loan_Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>11106243.00000</td>\n      <td>11106243.00000</td>\n      <td>11106243.00000</td>\n      <td>11106243.00000</td>\n      <td>11106243.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>13132.42598</td>\n      <td>140.83387</td>\n      <td>1.55425</td>\n      <td>641.25526</td>\n      <td>0.19031</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>10653.05310</td>\n      <td>15988.09176</td>\n      <td>3.17176</td>\n      <td>87.03325</td>\n      <td>0.39255</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.00000</td>\n      <td>-1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5000.00000</td>\n      <td>9.89000</td>\n      <td>0.00000</td>\n      <td>604.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>10000.00000</td>\n      <td>19.65000</td>\n      <td>0.00000</td>\n      <td>653.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>20000.00000</td>\n      <td>32.80000</td>\n      <td>0.00000</td>\n      <td>687.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1400000.00000</td>\n      <td>50000031.49000</td>\n      <td>10.00000</td>\n      <td>990.00000</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Get dataset summary and identify outliers\n",
    "consolidated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Loan_Amount          161845\n",
       "Debt_income_ratio    161845\n",
       "Emp_Length           161845\n",
       "Credit_Score         161845\n",
       "Loan_Status          161845\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "#counting outliers\n",
    "consolidated[(consolidated['Debt_income_ratio']>300) | (consolidated['Debt_income_ratio']<0) | (consolidated['Credit_Score']>850) | (consolidated['Credit_Score']<0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10901852, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "#Clean up data outliers\n",
    "consolidated.drop(consolidated[consolidated['Debt_income_ratio']>200].index, inplace = True)\n",
    "consolidated.drop(consolidated[consolidated['Debt_income_ratio']<0].index, inplace = True)\n",
    "consolidated.drop(consolidated[consolidated['Credit_Score']<0].index, inplace = True)\n",
    "consolidated.drop(consolidated[consolidated['Credit_Score']>850].index, inplace = True)\n",
    "consolidated.shape"
   ]
  },
  {
   "source": [
    "### Data Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since dataset is very large, we will extract a small sample from our datasaet and plot \n",
    "# sample_df = consolidated.sample(frac=0.1, replace=False, random_state=1)\n",
    "\n",
    "# plt.scatter(sample_df['Debt_income_ratio'],sample_df['Credit_Score'],c=sample_df['Loan_Status'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df['Debt_income_ratio'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df['Credit_Score'].plot.density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Class Imbalance\n",
    " "
   ]
  },
  {
   "source": [
    "### Method 1: Oversampling\n",
    "This involves duplicating the minority class. This can potentially lead to overfitting or biasing towards some of minority class outliers/data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " The count for y_train before oversample is:Counter({0: 6591467, 1: 1584922})\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data by using StandardScaler\n",
    "\n",
    "y = consolidated['Loan_Status']\n",
    "X = consolidated.drop('Loan_Status',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(f' The count for y_train before oversample is:{Counter(y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " The count for y_train after oversample is:Counter({0: 6591467, 1: 6591467})\n"
     ]
    }
   ],
   "source": [
    "# Oversampling the data\n",
    "over = RandomOverSampler(sampling_strategy='minority') # 'minority' can be replaced by a float < 1\n",
    "X_train_over,y_train_over = over.fit_resample(X_train_scaled,y_train)\n",
    "print(f' The count for y_train after oversample is:{Counter(y_train_over)}')"
   ]
  },
  {
   "source": [
    "### Method 2: Undersampling\n",
    "This involves removing samples from the majority class. This can potentially lead to losing some of teh important infromation from the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " The count for y_train after undersample is:Counter({0: 1584922, 1: 1584922})\n"
     ]
    }
   ],
   "source": [
    "# Undersampling the data\n",
    "under = RandomUnderSampler(sampling_strategy='majority') # 'majority' can be replaced by a float < 1\n",
    "X_train_under,y_train_under = under.fit_resample(X_train_scaled,y_train)\n",
    "print(f' The count for y_train after undersample is:{Counter(y_train_under)}')"
   ]
  },
  {
   "source": [
    "### Mehtod 3: Oversampling SMOTE\n",
    "The synthetic minority oversampling technique (SMOTE) is another oversampling approach where new instances of minority class are interpolated. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " The count for y_train after SMOTE oversample is:Counter({0: 6591467, 1: 6591467})\n"
     ]
    }
   ],
   "source": [
    "# Resampling using SMOTE the data\n",
    "smote = SMOTE(sampling_strategy='auto') \n",
    "X_train_smote,y_train_smote = smote.fit_resample(X_train_scaled,y_train)\n",
    "print(f' The count for y_train after SMOTE oversample is:{Counter(y_train_smote)}')"
   ]
  },
  {
   "source": [
    "### Method 4: Cluster Centroid Umdersampling\n",
    "The algorithm identifies clusters of the majority class, then generates synthetic data points, called centroids, that are representative of the clusters. The majority class is then undersampled down to the size of the minority class."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0c983efdabae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Resampling using Cluster Centroids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClusterCentroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train_cc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_cc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' The count for y_train after CC undersample is:{Counter(y_train_cc)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_strategy_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"n_clusters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 X_new, y_new = self._generate_sample(\n\u001b[1;32m    174\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1016\u001b[0m             centers_init = self._init_centroids(\n\u001b[1;32m   1017\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m                 random_state=random_state)\n\u001b[0m\u001b[1;32m   1019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initialization complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_init_centroids\u001b[0;34m(self, X, x_squared_norms, init, random_state, init_size)\u001b[0m\n\u001b[1;32m    934\u001b[0m             centers, _ = _kmeans_plusplus(X, n_clusters,\n\u001b[1;32m    935\u001b[0m                                           \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                                           x_squared_norms=x_squared_norms)\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_kmeans_plusplus\u001b[0;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# Compute distances to center candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         distance_to_candidates = euclidean_distances(\n\u001b[0;32m--> 124\u001b[0;31m             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# update closest distances squared and potential for each candidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Resampling using Cluster Centroids\n",
    "cc = ClusterCentroids() \n",
    "X_train_cc,y_train_cc = cc.fit_resample(X_train_scaled,y_train)\n",
    "print(f' The count for y_train after CC undersample is:{Counter(y_train_cc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_names = ['Imbalanced', 'Oversampling', 'Undersampling', 'SMOTE', 'ClusterCentroids']\n",
    "X_train_sets = [X_train_scaled, X_train_over, X_train_under, X_train_smote, X_train_cc]\n",
    "y_train_sets = [y_train, y_train_over, y_train_under, y_train_smote, y_train_cc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This is the result from Imbalanced method\n",
      "accuracy: 0.886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93   2197156\n",
      "           1       0.76      0.61      0.67    528307\n",
      "\n",
      "    accuracy                           0.89   2725463\n",
      "   macro avg       0.83      0.78      0.80   2725463\n",
      "weighted avg       0.88      0.89      0.88   2725463\n",
      "\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "This is the result from Oversampling method\n",
      "accuracy: 0.877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92   2197156\n",
      "           1       0.63      0.85      0.73    528307\n",
      "\n",
      "    accuracy                           0.88   2725463\n",
      "   macro avg       0.80      0.87      0.82   2725463\n",
      "weighted avg       0.90      0.88      0.88   2725463\n",
      "\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "This is the result from Undersampling method\n",
      "accuracy: 0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92   2197156\n",
      "           1       0.63      0.86      0.73    528307\n",
      "\n",
      "    accuracy                           0.88   2725463\n",
      "   macro avg       0.80      0.87      0.82   2725463\n",
      "weighted avg       0.90      0.88      0.88   2725463\n",
      "\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "This is the result from SMOTE method\n",
      "accuracy: 0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92   2197156\n",
      "           1       0.63      0.86      0.73    528307\n",
      "\n",
      "    accuracy                           0.88   2725463\n",
      "   macro avg       0.80      0.87      0.82   2725463\n",
      "weighted avg       0.90      0.88      0.88   2725463\n",
      "\n",
      "------------------------------------\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run Logistic Regression Loop \n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs',max_iter=100)\n",
    "\n",
    "for session in range(len(X_train_sets)):\n",
    "\n",
    "    lr.fit(X_train_sets[session], y_train_sets[session])\n",
    "    y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "    print(f'This is the result from {session_names[session]} method')\n",
    "    print(f'accuracy: {accuracy_score(y_test, y_pred):.3f}')\n",
    "    # confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # print(confusion_matrix)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('------------------------------------')\n",
    "    print('------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('mlenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "342355481251568d946b81fa6f1ceaf1668cb9b97b9b0e52534cee47996a832f"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}