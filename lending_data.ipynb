{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Lending ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "sns.set() \n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "# accepted applicants data file \n",
    "raw_accepted = pd.read_csv('../Archive/accepted_2007_to_2018Q4.csv') \n",
    "# rejected applicants data file\n",
    "raw_rejected = pd.read_csv('../Archive/rejected_2007_to_2018Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data copy \n",
    "file_rejected = raw_rejected.copy()\n",
    "file_rejected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data copy \n",
    "file_accepted = raw_accepted.copy()\n",
    "file_accepted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 1 .Binary classification model to accept or reject loan application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Only keep those columns that are going to be used for analysis \n",
    " \n",
    "Application Date - date does not play a role in getting rejected or accepted unless you beleive in Numerology \n",
    "Loan Title - For out initial model we have left this out since it did not add a lot of value to the rejected decison. \n",
    "Zip Code - We saw people getting accepted and rejected for teh same zipcodes so we think that zipcode does not have a big impact on loan application\n",
    "Policy Code- This is our target column so we have it but made sure it was all '0'\n",
    "\n",
    "'''\n",
    "file_rejected = file_rejected[['Amount Requested', 'Risk_Score',\n",
    "       'Debt-To-Income Ratio', 'Employment Length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rejected['Label_target'] = 0\n",
    "file_rejected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extact the same columms from the  accepted applicant df to match the rejected data set. We will combine this dataset at a later set to make a complete data frame that will be used to train teh classification model. \n",
    "\n",
    "file_accepted = file_accepted[['loan_amnt', 'fico_range_low', 'fico_range_high', 'dti', 'emp_length']]\n",
    "file_accepted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average FICO score for the high and low range of the applicant\n",
    "file_accepted['average'] = (file_accepted['fico_range_low'] + file_accepted['fico_range_high'])*0.5\n",
    "\n",
    "# Drop the FICO high and low scores \n",
    "file_accepted = file_accepted.drop(columns=['fico_range_low','fico_range_high'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a target label column for accepted df\n",
    "file_accepted['label_target']=1   \n",
    "file_accepted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for accepted and rejected df\n",
    "file_accepted.rename(columns= {'loan_amnt': 'Loan_Amount', 'dti': 'Debt_income_ratio', 'average': 'Credit_Score', 'label_target': 'Loan_Status', 'emp_length':'Emp_Length'}, inplace=True)\n",
    "\n",
    "file_rejected.rename(columns= {'Amount Requested': 'Loan_Amount', 'Debt-To-Income Ratio': 'Debt_income_ratio', 'Risk_Score': 'Credit_Score', 'Label_target': 'Loan_Status', 'Employment Length':'Emp_Length'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange columns in rejected df to concat with the accepted df\n",
    "file_rejected = file_rejected[['Loan_Amount', 'Debt_income_ratio', 'Emp_Length', 'Credit_Score', 'Loan_Status']]\n",
    "file_rejected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove % from Debt_income_ratio\n",
    "file_rejected['Debt_income_ratio'] = file_rejected['Debt_income_ratio'].str.replace('%','')\n",
    "file_rejected['Debt_income_ratio'] = pd.to_numeric(file_rejected['Debt_income_ratio'])\n",
    "file_rejected.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of NaNs in rejected dataset\n",
    "\n",
    "file_rejected.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of NaNs in accepted dataset\n",
    "\n",
    "file_accepted.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs from both datasets\n",
    "\n",
    "file_accepted = file_accepted.dropna()\n",
    "file_rejected = file_rejected.dropna()\n",
    "print(f'There are {file_accepted.shape[0]} succesfull applications and {file_rejected.shape[0]} unsuccessful applications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data sets \n",
    "# file_accepted.to_csv('../Archive/accepted_data_clean', index=False)\n",
    "# file_rejected.to_csv('../Archive/rejected_data_clean', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate the two dataframes to single \n",
    "consolidated = pd.concat([file_accepted, file_rejected], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in Emp_length col\n",
    "consolidated['Emp_Length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the strings years, <,>,+ from Emp_length\n",
    "\n",
    "consolidated['Emp_Length'] = consolidated['Emp_Length'].replace('10+ years','10')\n",
    "consolidated['Emp_Length'] = consolidated['Emp_Length'].replace('< 1 year','0')\n",
    "consolidated['Emp_Length'] = consolidated['Emp_Length'].replace('1 year','1')\n",
    "consolidated['Emp_Length'] = consolidated['Emp_Length'].str.replace(' years','')\n",
    "consolidated['Emp_Length'] = consolidated['Emp_Length'].replace(' ','')\n",
    "consolidated['Emp_Length'] = pd.to_numeric(consolidated['Emp_Length'])\n",
    "consolidated['Emp_Length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset summary and identify outliers\n",
    "consolidated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting outliers\n",
    "consolidated[(consolidated['Debt_income_ratio']>300) | (consolidated['Debt_income_ratio']<0) | (consolidated['Credit_Score']>850) | (consolidated['Credit_Score']<0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up data outliers\n",
    "consolidated.drop(consolidated[consolidated['Debt_income_ratio']>200].index, inplace = True)\n",
    "consolidated.drop(consolidated[consolidated['Debt_income_ratio']<0].index, inplace = True)\n",
    "consolidated.drop(consolidated[consolidated['Credit_Score']<0].index, inplace = True)\n",
    "consolidated.drop(consolidated[consolidated['Credit_Score']>850].index, inplace = True)\n",
    "consolidated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inital Run by sampling the small subset of data  to make sure the cide runs \n",
    "consolidated = consolidated.sample(frac=0.08, replace=False, random_state=1)\n",
    "consolidated.shape"
   ]
  },
  {
   "source": [
    "### Data Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since dataset is very large, we will extract a small sample from our datasaet and plot \n",
    "# sample_df = consolidated.sample(frac=0.1, replace=False, random_state=1)\n",
    "\n",
    "# plt.scatter(sample_df['Debt_income_ratio'],sample_df['Credit_Score'],c=sample_df['Loan_Status'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df['Debt_income_ratio'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df['Credit_Score'].plot.density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Class Imbalance\n",
    " "
   ]
  },
  {
   "source": [
    "### Method 1: Oversampling\n",
    "This involves duplicating the minority class. This can potentially lead to overfitting or biasing towards some of minority class outliers/data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data by using StandardScaler\n",
    "\n",
    "y = consolidated['Loan_Status']\n",
    "X = consolidated.drop('Loan_Status',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(f' The count for y_train before oversample is:{Counter(y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling the data\n",
    "over = RandomOverSampler(sampling_strategy='minority') # 'minority' can be replaced by a float < 1\n",
    "X_train_over,y_train_over = over.fit_resample(X_train_scaled,y_train)\n",
    "print(f' The count for y_train after oversample is:{Counter(y_train_over)}')"
   ]
  },
  {
   "source": [
    "### Method 2: Undersampling\n",
    "This involves removing samples from the majority class. This can potentially lead to losing some of teh important infromation from the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling the data\n",
    "under = RandomUnderSampler(sampling_strategy='majority') # 'majority' can be replaced by a float < 1\n",
    "X_train_under,y_train_under = under.fit_resample(X_train_scaled,y_train)\n",
    "print(f' The count for y_train after undersample is:{Counter(y_train_under)}')"
   ]
  },
  {
   "source": [
    "### Mehtod 3: Oversampling SMOTE\n",
    "The synthetic minority oversampling technique (SMOTE) is another oversampling approach where new instances of minority class are interpolated. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling using SMOTE the data\n",
    "smote = SMOTE(sampling_strategy='auto') \n",
    "X_train_smote,y_train_smote = smote.fit_resample(X_train_scaled,y_train)\n",
    "print(f' The count for y_train after SMOTE oversample is:{Counter(y_train_smote)}')"
   ]
  },
  {
   "source": [
    "### Method 4: Cluster Centroid Umdersampling\n",
    "The algorithm identifies clusters of the majority class, then generates synthetic data points, called centroids, that are representative of the clusters. The majority class is then undersampled down to the size of the minority class."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Resampling using Cluster Centroids\n",
    "# cc = ClusterCentroids() \n",
    "# X_train_cc,y_train_cc = cc.fit_resample(X_train_scaled,y_train)\n",
    "# print(f' The count for y_train after CC undersample is:{Counter(y_train_cc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_names = ['Imbalanced', 'Oversampling', 'Undersampling', 'SMOTE'] # CC is not running right now\n",
    "X_train_sets = [X_train_scaled, X_train_over, X_train_under, X_train_smote]\n",
    "y_train_sets = [y_train, y_train_over, y_train_under, y_train_smote]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Logistic Regression Loop \n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs',max_iter=100)\n",
    "\n",
    "for session in range(len(X_train_sets)):\n",
    "\n",
    "    lr.fit(X_train_sets[session], y_train_sets[session])\n",
    "    y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "    print(f'This is the result from {session_names[session]} method')\n",
    "    print(f'accuracy: {accuracy_score(y_test, y_pred):.3f}')\n",
    "    # confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # print(confusion_matrix)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('------------------------------------')\n",
    "    print('------------------------------------')\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Naive Bayes Classification Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run  NB Gaussian Loop\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "mnb = GaussianNB()\n",
    "\n",
    "for session in range(len(X_train_sets)):\n",
    "\n",
    "    mnb.fit(X_train_sets[session], y_train_sets[session])\n",
    "    y_pred = mnb.predict(X_test_scaled)\n",
    "\n",
    "    print(f'This is the result from {session_names[session]} method')\n",
    "    print(f'accuracy: {accuracy_score(y_test, y_pred):.3f}')\n",
    "    # confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # print(confusion_matrix)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('------------------------------------')\n",
    "    print('------------------------------------')\n"
   ]
  },
  {
   "source": [
    "### Support Vector Machine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run  NB Gaussian Loop\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='poly') # other kernels : linear, rbf, sigmoid , Larger C more penalty for wrong classification\n",
    "\n",
    "for session in range(len(X_train_sets)):\n",
    "\n",
    "    svm.fit(X_train_sets[session], y_train_sets[session])\n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "    print(f'This is the result from {session_names[session]} method')\n",
    "    print(f'accuracy: {accuracy_score(y_test, y_pred):.3f}')\n",
    "    # confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # print(confusion_matrix)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('------------------------------------')\n",
    "    print('------------------------------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Decision Tree Algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Decision Tree Loop \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "for session in range(len(X_train_sets)):\n",
    "    dtc.fit(X_train_sets[session],y_train_sets[session])\n",
    "    y_pred = dtc.predict(X_test_scaled)\n",
    "\n",
    "    print(f'This is the result from {session_names[session]} method')\n",
    "    print(f'accuracy: {accuracy_score(y_test, y_pred):.3f}')\n",
    "    # confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # print(confusion_matrix)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('------------------------------------')\n",
    "    print('------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('mlenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "342355481251568d946b81fa6f1ceaf1668cb9b97b9b0e52534cee47996a832f"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}